{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* Setup\n",
    "    * Libraries\n",
    "    * Constants\n",
    "\n",
    "    * Functions\n",
    "    * Configurations\n",
    "* Data Exploration\n",
    "    * Model 1\n",
    "    * Evaluation Model 1\n",
    "    * Re-train Model 1\n",
    "    * Evaluation Model 1.1\n",
    "* Optimizer Experiment\n",
    "* Kernel-size & Epoch Experiment\n",
    "* Model Comparison\n",
    "    * Evaluation of best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<\n",
    "!pip install -r requirements.txt\n",
    "!pip list\n",
    ">\n",
    "\"\"\";\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    accuracy_score, \n",
    "    f1_score, )\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR: str = './data'\n",
    "TRAIN_DATA_DIR: str = './data/train_data'\n",
    "TEST_DATA_DIR: str = './data/test_data'\n",
    "\n",
    "# Default learning rate and batch size\n",
    "LR: float = 1e-4\n",
    "MINI_BATCH_SIZE: int = 128\n",
    "\n",
    "CLASSES: Dict[int, str] = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "# Search space is e.g., (4) kernel size: (8, 16, 32, 64) epochs\n",
    "SEARCH_SPACE: Dict[int, List[int]] = {\n",
    "    4: [8, 16, 32, 64],\n",
    "    6: [8, 16, 32, 64],\n",
    "    8: [8, 16, 32, 64],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir_and_check_data(_data_dir=DATA_DIR):\n",
    "    \"\"\"\n",
    "    Checks if a data directory exists and if it is populated.\n",
    "    Download of data starts automatically if directory does \n",
    "    not exists or exists and is empty.\n",
    "    \"\"\"\n",
    "    if os.path.exists(_data_dir) and len(os.listdir(_data_dir)) == 0:\n",
    "        print(\"Data directory exists.\", end='\\n\\n')\n",
    "        TRAIN_DATA = torchvision.datasets.FashionMNIST(\n",
    "            root=TRAIN_DATA_DIR,\n",
    "            train=True,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.ToTensor()]),\n",
    "            download=True,\n",
    "        )\n",
    "        TEST_DATA = torchvision.datasets.FashionMNIST(\n",
    "            root=TEST_DATA_DIR,\n",
    "            train=False,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.ToTensor()]),\n",
    "            download=True,\n",
    "        )\n",
    "        return TRAIN_DATA, TEST_DATA\n",
    "    \n",
    "    elif os.path.exists(_data_dir) and len(os.listdir(_data_dir)) != 0:\n",
    "        print(\"Data directory exists and is already populated.\",)\n",
    "        TRAIN_DATA = torchvision.datasets.FashionMNIST(\n",
    "            root=TRAIN_DATA_DIR,\n",
    "            train=True,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.ToTensor()]),\n",
    "            download=False,\n",
    "        )\n",
    "        TEST_DATA = torchvision.datasets.FashionMNIST(\n",
    "            root=TEST_DATA_DIR,\n",
    "            train=False,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.ToTensor()]),\n",
    "            download=False,\n",
    "        )\n",
    "        return TRAIN_DATA, TEST_DATA\n",
    "        \n",
    "    else:\n",
    "        print(f\"Create '{_data_dir}' directory.\", end='\\n\\n')\n",
    "        os.makedirs(_data_dir)\n",
    "\n",
    "        print(\"Data directory exists.\", end='\\n\\n')\n",
    "        TRAIN_DATA = torchvision.datasets.FashionMNIST(\n",
    "            root=TRAIN_DATA_DIR,\n",
    "            train=True,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.ToTensor()]),\n",
    "            download=True,\n",
    "        )\n",
    "        TEST_DATA = torchvision.datasets.FashionMNIST(\n",
    "            root=TEST_DATA_DIR,\n",
    "            train=False,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.ToTensor()]),\n",
    "            download=True,\n",
    "        )\n",
    "        return TRAIN_DATA, TEST_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_one_image(\n",
    "    data, image_id: int, \n",
    "    size: Tuple[int, int] = (500, 500)\n",
    "):\n",
    "    \"\"\" Visualize one image at a time given the image ID.\n",
    "    \"\"\"\n",
    "    _img, _label = data[image_id]\n",
    "    fig = px.imshow(\n",
    "        torchvision.transforms.ToPILImage()(_img),\n",
    "        title=f'Example: {image_id} <br>Label     : { CLASSES[_label]}',\n",
    "        color_continuous_scale='RdBu_r', \n",
    "        origin='upper',\n",
    "        height=size[0],\n",
    "        width=size[1],\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    \"\"\" Wrapper to keep track of elapsed time of experiments.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def _timer(*args, **kwargs):\n",
    "        _start = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        _end = time.perf_counter()\n",
    "        _elapsed_time = _end - _start\n",
    "        print(f\"Elapsed time: {_elapsed_time:.4f} seconds.\")\n",
    "        return value, _elapsed_time\n",
    "    return _timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reset(m) -> None:\n",
    "    \"\"\" Reset weigths before each experiment!\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(eval_model):\n",
    "    \"\"\" Routine to evaluate the FashionMnist models.\n",
    "    \"\"\"\n",
    "    fashion_mnist_eval_dataloader = torch.utils.data.DataLoader(\n",
    "        TEST_DATA, batch_size=10000, shuffle=False, )\n",
    "\n",
    "    eval_mini_batch_losses = []\n",
    "\n",
    "    for _, (images, labels) in enumerate(fashion_mnist_eval_dataloader):\n",
    "\n",
    "        output = eval_model(images)\n",
    "\n",
    "        loss = nn.NLLLoss()(output, labels)\n",
    "\n",
    "        eval_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "    y_true = TEST_DATA.targets\n",
    "    y_pred = torch.argmax(\n",
    "        eval_model(iter(fashion_mnist_eval_dataloader).next()[0]), dim=1, )\n",
    "    \n",
    "    return (\n",
    "        np.mean(eval_mini_batch_losses), \n",
    "        accuracy_score(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "        ),\n",
    "        classification_report(\n",
    "            y_true, \n",
    "            y_pred,\n",
    "        ),\n",
    "        confusion_matrix(\n",
    "            y_true, \n",
    "            y_pred,\n",
    "        ),\n",
    "        f1_score(\n",
    "            y_true, \n",
    "            y_pred,\n",
    "            average='weighted',\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_experiments_matrix(\n",
    "    metric_matrix,\n",
    "    title: str = 'Model Experiment',\n",
    "    xlabel: str = \"Class Accuracies\",\n",
    "    ylabel: str = \"Model\",\n",
    "    colorlabel: str = \"Hits\",\n",
    "):\n",
    "    \"\"\" Plots the confusion matrix of an experiment.\n",
    "    \"\"\"\n",
    "    fig = px.imshow(\n",
    "        metric_matrix,\n",
    "        title=title,\n",
    "        template='none',\n",
    "        labels=dict(\n",
    "            x=xlabel, \n",
    "            y=ylabel, \n",
    "            color=colorlabel,\n",
    "        ),\n",
    "        x=[*CLASSES.values()],\n",
    "        y=[*CLASSES.values()],\n",
    "        aspect='equal',\n",
    "        color_continuous_scale='RdBu',\n",
    "        zmin=0, \n",
    "        zmax=1000,\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cpu\n",
      "1.21.4\n",
      "Notebook with cpu computation enabled.\n",
      "\n",
      "Data directory exists and is already populated.\n",
      "Number of experiments: 12\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "# Library settings\n",
    "os.environ['TZ'] = 'Europe/London'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(f'Notebook with {str(device)} computation enabled.', end='\\n\\n')\n",
    "\n",
    "# Download data\n",
    "TRAIN_DATA, TEST_DATA = check_dir_and_check_data(DATA_DIR)\n",
    "\n",
    "# Sanity Check\n",
    "assert len(TRAIN_DATA) == 60000\n",
    "assert len(TEST_DATA) == 10000\n",
    "\n",
    "# Experiments\n",
    "print(f\"Number of experiments: {len(SEARCH_SPACE.keys()) * len(SEARCH_SPACE[4])}\")\n",
    "\n",
    "# Plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"520px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_84.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_id = np.random.randint(len(TRAIN_DATA), size=1)[0]\n",
    "visualize_one_image(TRAIN_DATA, image_id, size=(400, 500)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/train_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/test_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(type(TRAIN_DATA))\n",
    "print(type(TEST_DATA))\n",
    "print(TRAIN_DATA)\n",
    "print(TEST_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Model 1 is the first implementation. Its aim is to be slightly better than the baseline. That is an accuracy greater than 1/10 = 0.1. The class FashionMnist is set up to be used throughout the notebook. The experiments later will focus on the kernel size and the epochs. Hence the kernel size and padding are parmeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnist(nn.Module):\n",
    "    \"\"\" Defined model for this notebook.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel_size: int, \n",
    "        padding: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param kernel_size: Variable kernel size for different CNNs.\n",
    "        :param padding: Padding respective to the kernel size.\n",
    "        \"\"\"\n",
    "        super(FashionMnist, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=kernel_size, \n",
    "            stride=1, padding=padding, )\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=2, stride=2, padding=0, )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=kernel_size, \n",
    "            stride=1, padding=padding, )\n",
    "        self.pool2 = nn.MaxPool2d(\n",
    "            kernel_size=2, stride=2, padding=0, )\n",
    "        \n",
    "        self.linear1 = nn.Linear(16 * 4 * 4, 120, bias=True, )\n",
    "        self.relu1 = nn.ReLU(inplace=True, )\n",
    "        self.linear2 = nn.Linear(120, 84, bias=True, )\n",
    "        self.relu2 = nn.ReLU(inplace=True,)\n",
    "        self.linear3 = nn.Linear(84, 10, )\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1, )\n",
    "    \n",
    "    def forward(self, images):\n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def train_model_1(\n",
    "    num_epochs: int, \n",
    "    kernel_size: int = 5, \n",
    "    padding: int = 0,\n",
    "    mini_batch_size = MINI_BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    criterion=nn.NLLLoss(),\n",
    "):  \n",
    "    \"\"\"\n",
    "    Function to execute the training of model_1.\n",
    "    All parameters are fixed, except for the epochs.\n",
    "    \"\"\"\n",
    "    # Inputs fixed for first model\n",
    "    _model_1 = FashionMnist(kernel_size, padding)\n",
    "    _model_1.apply(weight_reset)\n",
    "    _model_1 = _model_1.to(device)\n",
    "    _model_1.train()\n",
    "    \n",
    "    optimizer = optim.SGD(params=_model_1.parameters(), lr=LR, )\n",
    "    criterion.to(device)\n",
    "    \n",
    "    fashion_mnist_train_dataloader = torch.utils.data.DataLoader(\n",
    "    TRAIN_DATA, batch_size=MINI_BATCH_SIZE, shuffle=True, )\n",
    "\n",
    "    train_epoch_losses_model_1 = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_mini_batch_losses = []\n",
    "\n",
    "        for _, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = _model_1(images)\n",
    "            _model_1.zero_grad()\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "        train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "        train_epoch_losses_model_1.append(train_epoch_loss)\n",
    "\n",
    "        print(f'Epoch {epoch}: {train_epoch_loss:.5}')\n",
    "    return _model_1, train_epoch_losses_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 2.3045\n",
      "Epoch 1: 2.304\n",
      "Epoch 2: 2.3035\n",
      "Epoch 3: 2.303\n",
      "Epoch 4: 2.3026\n",
      "Epoch 5: 2.3021\n",
      "Epoch 6: 2.3016\n",
      "Epoch 7: 2.3011\n",
      "Epoch 8: 2.3007\n",
      "Epoch 9: 2.3002\n",
      "Elapsed time: 158.1950 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Train model 1 and catch the model aswell as the losses\n",
    "model_1, model_1_losses = train_model_1(num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_89.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(\n",
    "    model_1[1],\n",
    "    title='Model_1 Loss',\n",
    "    labels={\n",
    "        'index': 'Training Epoch',\n",
    "        'value': 'Loss',\n",
    "        'variable': 'Model',\n",
    "    },\n",
    "    template='none',\n",
    "    log_y=False,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\"\"\"\n",
    "Interestingly the loss has a linear scope. I guess the plot is so much \n",
    "zoomed in (only 10 epochs) that the slope appears linear. The conclusion\n",
    "is that more epochs are needed and this model is a true 'vanilla'.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_loss, model_1_acc, model_1_report, model_1_cm, model_1_f1 = evaluate_model(model_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2998476028442383\n",
      "Accuracy: 0.1005\n",
      "F1-score: 0.027027049140613258\n",
      "Classiification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.12      0.90      0.20      1000\n",
      "           3       0.05      0.10      0.07      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.02      0.10      0.03     10000\n",
      "weighted avg       0.02      0.10      0.03     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {model_1_loss}\")\n",
    "print(f\"Accuracy: {model_1_acc}\")\n",
    "print(f\"F1-score: {model_1_f1}\")\n",
    "print(\"Classiification report:\")\n",
    "print(model_1_report)\n",
    "\n",
    "\"\"\"\n",
    "The accuracy confirms the previous conclusion the model barely started \n",
    "to learn. The accuracy is just above 0.1. The classification report\n",
    "confirms that aswell. Interestingly the model started to learn one class\n",
    "first.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiments_matrix(\n",
    "    model_1_cm, title='Model_1 Experiment', \n",
    "    xlabel='True Label', \n",
    "    ylabel='Predicted Label',\n",
    "    colorlabel='Hits', )\n",
    "\n",
    "\"\"\"\n",
    "The confusion matrix mirrors the classification report. One class is learned\n",
    "first.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Train Model 1\n",
    "Model 1 showed that one class appears to be learned first. To test this hypothesis I retrain the model with more epochs and expect more classes to be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 2.307\n",
      "Epoch 1: 2.3065\n",
      "Epoch 2: 2.3061\n",
      "Epoch 3: 2.3057\n",
      "Epoch 4: 2.3053\n",
      "Epoch 5: 2.3048\n",
      "Epoch 6: 2.3044\n",
      "Epoch 7: 2.304\n",
      "Epoch 8: 2.3036\n",
      "Epoch 9: 2.3032\n",
      "Epoch 10: 2.3028\n",
      "Epoch 11: 2.3024\n",
      "Epoch 12: 2.3019\n",
      "Epoch 13: 2.3015\n",
      "Epoch 14: 2.3011\n"
     ]
    }
   ],
   "source": [
    "model_1_1, model_1_1_losses = train_model_1(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_1_loss, model_1_1_acc, model_1_1_report, model_1_1_cm, model_1_1_f1 = evaluate_model(model_1_1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2787866592407227\n",
      "Accuracy: 0.1131\n",
      "F1-score: 0.042484792396233095\n",
      "Classiification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.05      0.10      0.07      1000\n",
      "           5       0.88      0.08      0.14      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.12      0.95      0.22      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.11     10000\n",
      "   macro avg       0.10      0.11      0.04     10000\n",
      "weighted avg       0.10      0.11      0.04     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {model_1_1_loss}\")\n",
    "print(f\"Accuracy: {model_1_1_acc}\")\n",
    "print(f\"F1-score: {model_1_1_f1}\")\n",
    "print(\"Classiification report:\")\n",
    "print(model_1_1_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiments_matrix(\n",
    "    model_1_1_cm, \n",
    "    title='Model_1 Experiment [2]', \n",
    "    xlabel='True Label', \n",
    "    ylabel='Predicted Label', \n",
    "    colorlabel='Hits', )\n",
    "\n",
    "\"\"\"\n",
    "The classification report and the confusion matrix provide evidence\n",
    "to confirm the hypothesis. The classes seem to be learned 'one-by-one'\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best optimizer\n",
    "model = FashionMnist(5, 0)\n",
    "model = model.to(device)\n",
    "\n",
    "# Data\n",
    "fashion_mnist_train_dataloader = torch.utils.data.DataLoader(\n",
    "    TRAIN_DATA, batch_size=MINI_BATCH_SIZE, shuffle=True, )\n",
    "\n",
    "optimizers = [\n",
    "    torch.optim.Adadelta(model.parameters(), lr=LR,),\n",
    "    torch.optim.Adagrad(model.parameters(), lr=LR,),\n",
    "    torch.optim.Adam(model.parameters(), lr=LR,),\n",
    "    torch.optim.RMSprop(model.parameters(), lr=LR,),\n",
    "    torch.optim.SGD(model.parameters(), lr=LR,),  \n",
    "]\n",
    "\n",
    "# Hint from lecture, that nll is better?\n",
    "criteria = [\n",
    "    torch.nn.NLLLoss(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.0001\n",
      "    rho: 0.9\n",
      "    weight_decay: 0\n",
      ")\n",
      "Criterion: NLLLoss()\n",
      "\n",
      "Epoch: 0 train-loss: 2.304752920228027\n",
      "Epoch: 1 train-loss: 2.304639879320222\n",
      "Epoch: 2 train-loss: 2.3045193213643804\n",
      "Epoch: 3 train-loss: 2.3044079300691322\n",
      "Epoch: 4 train-loss: 2.3042914572555118\n",
      "Epoch: 5 train-loss: 2.304179283093288\n",
      "Epoch: 6 train-loss: 2.3040664638283412\n",
      "Epoch: 7 train-loss: 2.3039517316228544\n",
      "Epoch: 8 train-loss: 2.303842895829093\n",
      "Epoch: 9 train-loss: 2.3037304319044165\n",
      "Epoch: 10 train-loss: 2.303625842401468\n",
      "Epoch: 11 train-loss: 2.303512620519219\n",
      "Epoch: 12 train-loss: 2.303403151823259\n",
      "Epoch: 13 train-loss: 2.3032860537327684\n",
      "Epoch: 14 train-loss: 2.303175117415406\n",
      "Epoch: 15 train-loss: 2.3030692870174643\n",
      "Epoch: 16 train-loss: 2.302957877929785\n",
      "Epoch: 17 train-loss: 2.3028486964545016\n",
      "Epoch: 18 train-loss: 2.3027388475088677\n",
      "Epoch: 19 train-loss: 2.302630601915469\n",
      "[[2.304752920228027, 2.304639879320222, 2.3045193213643804, 2.3044079300691322, 2.3042914572555118, 2.304179283093288, 2.3040664638283412, 2.3039517316228544, 2.303842895829093, 2.3037304319044165, 2.303625842401468, 2.303512620519219, 2.303403151823259, 2.3032860537327684, 2.303175117415406, 2.3030692870174643, 2.302957877929785, 2.3028486964545016, 2.3027388475088677, 2.302630601915469]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Optimizer: Adagrad (\n",
      "Parameter Group 0\n",
      "    eps: 1e-10\n",
      "    initial_accumulator_value: 0\n",
      "    lr: 0.0001\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "Criterion: NLLLoss()\n",
      "\n",
      "Epoch: 0 train-loss: 2.2627081367761086\n",
      "Epoch: 1 train-loss: 2.180890495589039\n",
      "Epoch: 2 train-loss: 2.085980851512982\n",
      "Epoch: 3 train-loss: 1.9867335128377495\n",
      "Epoch: 4 train-loss: 1.8869204017907573\n",
      "Epoch: 5 train-loss: 1.7906770662966567\n",
      "Epoch: 6 train-loss: 1.701089120622891\n",
      "Epoch: 7 train-loss: 1.6205009082232966\n",
      "Epoch: 8 train-loss: 1.5489305916117198\n",
      "Epoch: 9 train-loss: 1.4860463322861108\n",
      "Epoch: 10 train-loss: 1.4309364392050803\n",
      "Epoch: 11 train-loss: 1.382832447603059\n",
      "Epoch: 12 train-loss: 1.341013641753939\n",
      "Epoch: 13 train-loss: 1.3047008361897743\n",
      "Epoch: 14 train-loss: 1.2727850446823055\n",
      "Epoch: 15 train-loss: 1.2445609335706178\n",
      "Epoch: 16 train-loss: 1.2191897495977406\n",
      "Epoch: 17 train-loss: 1.1963536009859683\n",
      "Epoch: 18 train-loss: 1.1760137963142476\n",
      "Epoch: 19 train-loss: 1.157999258051549\n",
      "[[2.304752920228027, 2.304639879320222, 2.3045193213643804, 2.3044079300691322, 2.3042914572555118, 2.304179283093288, 2.3040664638283412, 2.3039517316228544, 2.303842895829093, 2.3037304319044165, 2.303625842401468, 2.303512620519219, 2.303403151823259, 2.3032860537327684, 2.303175117415406, 2.3030692870174643, 2.302957877929785, 2.3028486964545016, 2.3027388475088677, 2.302630601915469], [2.2627081367761086, 2.180890495589039, 2.085980851512982, 1.9867335128377495, 1.8869204017907573, 1.7906770662966567, 1.701089120622891, 1.6205009082232966, 1.5489305916117198, 1.4860463322861108, 1.4309364392050803, 1.382832447603059, 1.341013641753939, 1.3047008361897743, 1.2727850446823055, 1.2445609335706178, 1.2191897495977406, 1.1963536009859683, 1.1760137963142476, 1.157999258051549]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Criterion: NLLLoss()\n",
      "\n",
      "Epoch: 0 train-loss: 1.3135513071058147\n",
      "Epoch: 1 train-loss: 0.753661917979275\n",
      "Epoch: 2 train-loss: 0.6753041978711004\n",
      "Epoch: 3 train-loss: 0.628896613492132\n",
      "Epoch: 4 train-loss: 0.5964356950605347\n",
      "Epoch: 5 train-loss: 0.5712236427803283\n",
      "Epoch: 6 train-loss: 0.5509112968500743\n",
      "Epoch: 7 train-loss: 0.5344106643947203\n",
      "Epoch: 8 train-loss: 0.5194504688035196\n",
      "Epoch: 9 train-loss: 0.5050828069893282\n",
      "Epoch: 10 train-loss: 0.49453629791609516\n",
      "Epoch: 11 train-loss: 0.48326981677683684\n",
      "Epoch: 12 train-loss: 0.4736171671068236\n",
      "Epoch: 13 train-loss: 0.46541435879939147\n",
      "Epoch: 14 train-loss: 0.456563083284191\n",
      "Epoch: 15 train-loss: 0.45129557656072605\n",
      "Epoch: 16 train-loss: 0.44339002411502765\n",
      "Epoch: 17 train-loss: 0.4377056162621675\n",
      "Epoch: 18 train-loss: 0.4310129442448809\n",
      "Epoch: 19 train-loss: 0.4267545803142255\n",
      "[[2.304752920228027, 2.304639879320222, 2.3045193213643804, 2.3044079300691322, 2.3042914572555118, 2.304179283093288, 2.3040664638283412, 2.3039517316228544, 2.303842895829093, 2.3037304319044165, 2.303625842401468, 2.303512620519219, 2.303403151823259, 2.3032860537327684, 2.303175117415406, 2.3030692870174643, 2.302957877929785, 2.3028486964545016, 2.3027388475088677, 2.302630601915469], [2.2627081367761086, 2.180890495589039, 2.085980851512982, 1.9867335128377495, 1.8869204017907573, 1.7906770662966567, 1.701089120622891, 1.6205009082232966, 1.5489305916117198, 1.4860463322861108, 1.4309364392050803, 1.382832447603059, 1.341013641753939, 1.3047008361897743, 1.2727850446823055, 1.2445609335706178, 1.2191897495977406, 1.1963536009859683, 1.1760137963142476, 1.157999258051549], [1.3135513071058147, 0.753661917979275, 0.6753041978711004, 0.628896613492132, 0.5964356950605347, 0.5712236427803283, 0.5509112968500743, 0.5344106643947203, 0.5194504688035196, 0.5050828069893282, 0.49453629791609516, 0.48326981677683684, 0.4736171671068236, 0.46541435879939147, 0.456563083284191, 0.45129557656072605, 0.44339002411502765, 0.4377056162621675, 0.4310129442448809, 0.4267545803142255]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Optimizer: RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "Criterion: NLLLoss()\n",
      "\n",
      "Epoch: 0 train-loss: 1.0512422526569\n",
      "Epoch: 1 train-loss: 0.7273955299401842\n",
      "Epoch: 2 train-loss: 0.6705788934408728\n",
      "Epoch: 3 train-loss: 0.6355121100126807\n",
      "Epoch: 4 train-loss: 0.6082512067833434\n",
      "Epoch: 5 train-loss: 0.5853243775840508\n",
      "Epoch: 6 train-loss: 0.565576980807888\n",
      "Epoch: 7 train-loss: 0.5481405542222167\n",
      "Epoch: 8 train-loss: 0.5327024161815643\n",
      "Epoch: 9 train-loss: 0.5203996028727306\n",
      "Epoch: 10 train-loss: 0.5073587848687731\n",
      "Epoch: 11 train-loss: 0.49643460646875376\n",
      "Epoch: 12 train-loss: 0.487200616646423\n",
      "Epoch: 13 train-loss: 0.4785808470965957\n",
      "Epoch: 14 train-loss: 0.4702556541225295\n",
      "Epoch: 15 train-loss: 0.46275581467126226\n",
      "Epoch: 16 train-loss: 0.4556988843722638\n",
      "Epoch: 17 train-loss: 0.4493317171963039\n",
      "Epoch: 18 train-loss: 0.4427280684015644\n",
      "Epoch: 19 train-loss: 0.4356507512170877\n",
      "[[2.304752920228027, 2.304639879320222, 2.3045193213643804, 2.3044079300691322, 2.3042914572555118, 2.304179283093288, 2.3040664638283412, 2.3039517316228544, 2.303842895829093, 2.3037304319044165, 2.303625842401468, 2.303512620519219, 2.303403151823259, 2.3032860537327684, 2.303175117415406, 2.3030692870174643, 2.302957877929785, 2.3028486964545016, 2.3027388475088677, 2.302630601915469], [2.2627081367761086, 2.180890495589039, 2.085980851512982, 1.9867335128377495, 1.8869204017907573, 1.7906770662966567, 1.701089120622891, 1.6205009082232966, 1.5489305916117198, 1.4860463322861108, 1.4309364392050803, 1.382832447603059, 1.341013641753939, 1.3047008361897743, 1.2727850446823055, 1.2445609335706178, 1.2191897495977406, 1.1963536009859683, 1.1760137963142476, 1.157999258051549], [1.3135513071058147, 0.753661917979275, 0.6753041978711004, 0.628896613492132, 0.5964356950605347, 0.5712236427803283, 0.5509112968500743, 0.5344106643947203, 0.5194504688035196, 0.5050828069893282, 0.49453629791609516, 0.48326981677683684, 0.4736171671068236, 0.46541435879939147, 0.456563083284191, 0.45129557656072605, 0.44339002411502765, 0.4377056162621675, 0.4310129442448809, 0.4267545803142255], [1.0512422526569, 0.7273955299401842, 0.6705788934408728, 0.6355121100126807, 0.6082512067833434, 0.5853243775840508, 0.565576980807888, 0.5481405542222167, 0.5327024161815643, 0.5203996028727306, 0.5073587848687731, 0.49643460646875376, 0.487200616646423, 0.4785808470965957, 0.4702556541225295, 0.46275581467126226, 0.4556988843722638, 0.4493317171963039, 0.4427280684015644, 0.4356507512170877]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Criterion: NLLLoss()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train-loss: 2.3021860015926077\n",
      "Epoch: 1 train-loss: 2.3016213287931007\n",
      "Epoch: 2 train-loss: 2.3010558980360214\n",
      "Epoch: 3 train-loss: 2.3004841291065663\n",
      "Epoch: 4 train-loss: 2.2999145074693885\n",
      "Epoch: 5 train-loss: 2.2993400813674114\n",
      "Epoch: 6 train-loss: 2.2987705985111977\n",
      "Epoch: 7 train-loss: 2.2981988982096917\n",
      "Epoch: 8 train-loss: 2.297622959751056\n",
      "Epoch: 9 train-loss: 2.2970440707989592\n",
      "Epoch: 10 train-loss: 2.296466010465805\n",
      "Epoch: 11 train-loss: 2.2958798169581365\n",
      "Epoch: 12 train-loss: 2.2952950071932663\n",
      "Epoch: 13 train-loss: 2.2947003383880484\n",
      "Epoch: 14 train-loss: 2.2941039116906206\n",
      "Epoch: 15 train-loss: 2.2935039956432415\n",
      "Epoch: 16 train-loss: 2.292888142660991\n",
      "Epoch: 17 train-loss: 2.292272166148432\n",
      "Epoch: 18 train-loss: 2.2916409781238416\n",
      "Epoch: 19 train-loss: 2.2910027326042974\n",
      "[[2.304752920228027, 2.304639879320222, 2.3045193213643804, 2.3044079300691322, 2.3042914572555118, 2.304179283093288, 2.3040664638283412, 2.3039517316228544, 2.303842895829093, 2.3037304319044165, 2.303625842401468, 2.303512620519219, 2.303403151823259, 2.3032860537327684, 2.303175117415406, 2.3030692870174643, 2.302957877929785, 2.3028486964545016, 2.3027388475088677, 2.302630601915469], [2.2627081367761086, 2.180890495589039, 2.085980851512982, 1.9867335128377495, 1.8869204017907573, 1.7906770662966567, 1.701089120622891, 1.6205009082232966, 1.5489305916117198, 1.4860463322861108, 1.4309364392050803, 1.382832447603059, 1.341013641753939, 1.3047008361897743, 1.2727850446823055, 1.2445609335706178, 1.2191897495977406, 1.1963536009859683, 1.1760137963142476, 1.157999258051549], [1.3135513071058147, 0.753661917979275, 0.6753041978711004, 0.628896613492132, 0.5964356950605347, 0.5712236427803283, 0.5509112968500743, 0.5344106643947203, 0.5194504688035196, 0.5050828069893282, 0.49453629791609516, 0.48326981677683684, 0.4736171671068236, 0.46541435879939147, 0.456563083284191, 0.45129557656072605, 0.44339002411502765, 0.4377056162621675, 0.4310129442448809, 0.4267545803142255], [1.0512422526569, 0.7273955299401842, 0.6705788934408728, 0.6355121100126807, 0.6082512067833434, 0.5853243775840508, 0.565576980807888, 0.5481405542222167, 0.5327024161815643, 0.5203996028727306, 0.5073587848687731, 0.49643460646875376, 0.487200616646423, 0.4785808470965957, 0.4702556541225295, 0.46275581467126226, 0.4556988843722638, 0.4493317171963039, 0.4427280684015644, 0.4356507512170877], [2.3021860015926077, 2.3016213287931007, 2.3010558980360214, 2.3004841291065663, 2.2999145074693885, 2.2993400813674114, 2.2987705985111977, 2.2981988982096917, 2.297622959751056, 2.2970440707989592, 2.296466010465805, 2.2958798169581365, 2.2952950071932663, 2.2947003383880484, 2.2941039116906206, 2.2935039956432415, 2.292888142660991, 2.292272166148432, 2.2916409781238416, 2.2910027326042974]]\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train 5 models with constant inputs except for the optimizer.\n",
    "The losses are saved after each epoch and model.\n",
    "\"\"\";\n",
    "\n",
    "num_epochs = 20\n",
    "mini_batch_size = MINI_BATCH_SIZE\n",
    "\n",
    "overall_losses = []\n",
    "train_epoch_losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for criterion in criteria:\n",
    "\n",
    "        # reset model\n",
    "        model.apply(weight_reset)\n",
    "\n",
    "        train_epoch_losses = []\n",
    "        print(f\"Optimizer: {optimizer}\\nCriterion: {criterion}\\n\")\n",
    "        criterion.to(device)\n",
    "        #optimizer.to(device)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            train_mini_batch_losses = []\n",
    "            \n",
    "            for _, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "                model.zero_grad()\n",
    "                \n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                train_mini_batch_losses.append(loss.data.item())\n",
    "            \n",
    "            train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "            print('Epoch: {} train-loss: {}'.format(str(epoch), str(train_epoch_loss)))\n",
    "            \n",
    "            train_epoch_losses.append(train_epoch_loss)\n",
    "        overall_losses.append(train_epoch_losses)\n",
    "        print(overall_losses)\n",
    "        print(\"-\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_optimizers = pd.DataFrame(\n",
    "    overall_losses, \n",
    "    index=[\n",
    "        'Adadelta-NLL',\n",
    "        'Adagrad-NLL',\n",
    "        'Adam-NLL',\n",
    "        'RMSprop-NLL',\n",
    "        'SGD-NLL',\n",
    "    ],\n",
    "    columns=['Epoch_' + str(epoch) for epoch in list(range(1, 21, 1))],\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adadelta-NLL</th>\n",
       "      <th>Adagrad-NLL</th>\n",
       "      <th>Adam-NLL</th>\n",
       "      <th>RMSprop-NLL</th>\n",
       "      <th>SGD-NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Epoch_1</th>\n",
       "      <td>2.304753</td>\n",
       "      <td>2.262708</td>\n",
       "      <td>1.313551</td>\n",
       "      <td>1.051242</td>\n",
       "      <td>2.302186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_2</th>\n",
       "      <td>2.304640</td>\n",
       "      <td>2.180890</td>\n",
       "      <td>0.753662</td>\n",
       "      <td>0.727396</td>\n",
       "      <td>2.301621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_3</th>\n",
       "      <td>2.304519</td>\n",
       "      <td>2.085981</td>\n",
       "      <td>0.675304</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>2.301056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_4</th>\n",
       "      <td>2.304408</td>\n",
       "      <td>1.986734</td>\n",
       "      <td>0.628897</td>\n",
       "      <td>0.635512</td>\n",
       "      <td>2.300484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_5</th>\n",
       "      <td>2.304291</td>\n",
       "      <td>1.886920</td>\n",
       "      <td>0.596436</td>\n",
       "      <td>0.608251</td>\n",
       "      <td>2.299915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_6</th>\n",
       "      <td>2.304179</td>\n",
       "      <td>1.790677</td>\n",
       "      <td>0.571224</td>\n",
       "      <td>0.585324</td>\n",
       "      <td>2.299340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_7</th>\n",
       "      <td>2.304066</td>\n",
       "      <td>1.701089</td>\n",
       "      <td>0.550911</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>2.298771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_8</th>\n",
       "      <td>2.303952</td>\n",
       "      <td>1.620501</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.548141</td>\n",
       "      <td>2.298199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_9</th>\n",
       "      <td>2.303843</td>\n",
       "      <td>1.548931</td>\n",
       "      <td>0.519450</td>\n",
       "      <td>0.532702</td>\n",
       "      <td>2.297623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_10</th>\n",
       "      <td>2.303730</td>\n",
       "      <td>1.486046</td>\n",
       "      <td>0.505083</td>\n",
       "      <td>0.520400</td>\n",
       "      <td>2.297044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_11</th>\n",
       "      <td>2.303626</td>\n",
       "      <td>1.430936</td>\n",
       "      <td>0.494536</td>\n",
       "      <td>0.507359</td>\n",
       "      <td>2.296466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_12</th>\n",
       "      <td>2.303513</td>\n",
       "      <td>1.382832</td>\n",
       "      <td>0.483270</td>\n",
       "      <td>0.496435</td>\n",
       "      <td>2.295880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_13</th>\n",
       "      <td>2.303403</td>\n",
       "      <td>1.341014</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.487201</td>\n",
       "      <td>2.295295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_14</th>\n",
       "      <td>2.303286</td>\n",
       "      <td>1.304701</td>\n",
       "      <td>0.465414</td>\n",
       "      <td>0.478581</td>\n",
       "      <td>2.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_15</th>\n",
       "      <td>2.303175</td>\n",
       "      <td>1.272785</td>\n",
       "      <td>0.456563</td>\n",
       "      <td>0.470256</td>\n",
       "      <td>2.294104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_16</th>\n",
       "      <td>2.303069</td>\n",
       "      <td>1.244561</td>\n",
       "      <td>0.451296</td>\n",
       "      <td>0.462756</td>\n",
       "      <td>2.293504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_17</th>\n",
       "      <td>2.302958</td>\n",
       "      <td>1.219190</td>\n",
       "      <td>0.443390</td>\n",
       "      <td>0.455699</td>\n",
       "      <td>2.292888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_18</th>\n",
       "      <td>2.302849</td>\n",
       "      <td>1.196354</td>\n",
       "      <td>0.437706</td>\n",
       "      <td>0.449332</td>\n",
       "      <td>2.292272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_19</th>\n",
       "      <td>2.302739</td>\n",
       "      <td>1.176014</td>\n",
       "      <td>0.431013</td>\n",
       "      <td>0.442728</td>\n",
       "      <td>2.291641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_20</th>\n",
       "      <td>2.302631</td>\n",
       "      <td>1.157999</td>\n",
       "      <td>0.426755</td>\n",
       "      <td>0.435651</td>\n",
       "      <td>2.291003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Adadelta-NLL  Adagrad-NLL  Adam-NLL  RMSprop-NLL   SGD-NLL\n",
       "Epoch_1       2.304753     2.262708  1.313551     1.051242  2.302186\n",
       "Epoch_2       2.304640     2.180890  0.753662     0.727396  2.301621\n",
       "Epoch_3       2.304519     2.085981  0.675304     0.670579  2.301056\n",
       "Epoch_4       2.304408     1.986734  0.628897     0.635512  2.300484\n",
       "Epoch_5       2.304291     1.886920  0.596436     0.608251  2.299915\n",
       "Epoch_6       2.304179     1.790677  0.571224     0.585324  2.299340\n",
       "Epoch_7       2.304066     1.701089  0.550911     0.565577  2.298771\n",
       "Epoch_8       2.303952     1.620501  0.534411     0.548141  2.298199\n",
       "Epoch_9       2.303843     1.548931  0.519450     0.532702  2.297623\n",
       "Epoch_10      2.303730     1.486046  0.505083     0.520400  2.297044\n",
       "Epoch_11      2.303626     1.430936  0.494536     0.507359  2.296466\n",
       "Epoch_12      2.303513     1.382832  0.483270     0.496435  2.295880\n",
       "Epoch_13      2.303403     1.341014  0.473617     0.487201  2.295295\n",
       "Epoch_14      2.303286     1.304701  0.465414     0.478581  2.294700\n",
       "Epoch_15      2.303175     1.272785  0.456563     0.470256  2.294104\n",
       "Epoch_16      2.303069     1.244561  0.451296     0.462756  2.293504\n",
       "Epoch_17      2.302958     1.219190  0.443390     0.455699  2.292888\n",
       "Epoch_18      2.302849     1.196354  0.437706     0.449332  2.292272\n",
       "Epoch_19      2.302739     1.176014  0.431013     0.442728  2.291641\n",
       "Epoch_20      2.302631     1.157999  0.426755     0.435651  2.291003"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The experiment results in a pd.df with 5 columns and 20 epochs each.\n",
    "\"\"\";\n",
    "\n",
    "df_optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Combination=Adadelta-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>",
         "legendgroup": "Adadelta-NLL",
         "line": {
          "color": "#1F77B4",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Adadelta-NLL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Epoch_1",
          "Epoch_2",
          "Epoch_3",
          "Epoch_4",
          "Epoch_5",
          "Epoch_6",
          "Epoch_7",
          "Epoch_8",
          "Epoch_9",
          "Epoch_10",
          "Epoch_11",
          "Epoch_12",
          "Epoch_13",
          "Epoch_14",
          "Epoch_15",
          "Epoch_16",
          "Epoch_17",
          "Epoch_18",
          "Epoch_19",
          "Epoch_20"
         ],
         "xaxis": "x",
         "y": [
          2.304752920228027,
          2.304639879320222,
          2.3045193213643804,
          2.3044079300691322,
          2.3042914572555118,
          2.304179283093288,
          2.3040664638283412,
          2.3039517316228544,
          2.303842895829093,
          2.3037304319044165,
          2.303625842401468,
          2.303512620519219,
          2.303403151823259,
          2.3032860537327684,
          2.303175117415406,
          2.3030692870174643,
          2.302957877929785,
          2.3028486964545016,
          2.3027388475088677,
          2.302630601915469
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Combination=Adagrad-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>",
         "legendgroup": "Adagrad-NLL",
         "line": {
          "color": "#FF7F0E",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Adagrad-NLL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Epoch_1",
          "Epoch_2",
          "Epoch_3",
          "Epoch_4",
          "Epoch_5",
          "Epoch_6",
          "Epoch_7",
          "Epoch_8",
          "Epoch_9",
          "Epoch_10",
          "Epoch_11",
          "Epoch_12",
          "Epoch_13",
          "Epoch_14",
          "Epoch_15",
          "Epoch_16",
          "Epoch_17",
          "Epoch_18",
          "Epoch_19",
          "Epoch_20"
         ],
         "xaxis": "x",
         "y": [
          2.2627081367761086,
          2.180890495589039,
          2.085980851512982,
          1.9867335128377495,
          1.8869204017907573,
          1.7906770662966567,
          1.701089120622891,
          1.6205009082232966,
          1.5489305916117198,
          1.4860463322861108,
          1.4309364392050803,
          1.382832447603059,
          1.341013641753939,
          1.3047008361897743,
          1.2727850446823055,
          1.2445609335706178,
          1.2191897495977406,
          1.1963536009859683,
          1.1760137963142476,
          1.157999258051549
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Combination=Adam-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>",
         "legendgroup": "Adam-NLL",
         "line": {
          "color": "#2CA02C",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Adam-NLL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Epoch_1",
          "Epoch_2",
          "Epoch_3",
          "Epoch_4",
          "Epoch_5",
          "Epoch_6",
          "Epoch_7",
          "Epoch_8",
          "Epoch_9",
          "Epoch_10",
          "Epoch_11",
          "Epoch_12",
          "Epoch_13",
          "Epoch_14",
          "Epoch_15",
          "Epoch_16",
          "Epoch_17",
          "Epoch_18",
          "Epoch_19",
          "Epoch_20"
         ],
         "xaxis": "x",
         "y": [
          1.3135513071058147,
          0.753661917979275,
          0.6753041978711004,
          0.628896613492132,
          0.5964356950605347,
          0.5712236427803283,
          0.5509112968500743,
          0.5344106643947203,
          0.5194504688035196,
          0.5050828069893282,
          0.49453629791609516,
          0.48326981677683684,
          0.4736171671068236,
          0.46541435879939147,
          0.456563083284191,
          0.45129557656072605,
          0.44339002411502765,
          0.4377056162621675,
          0.4310129442448809,
          0.4267545803142255
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Combination=RMSprop-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>",
         "legendgroup": "RMSprop-NLL",
         "line": {
          "color": "#D62728",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "RMSprop-NLL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Epoch_1",
          "Epoch_2",
          "Epoch_3",
          "Epoch_4",
          "Epoch_5",
          "Epoch_6",
          "Epoch_7",
          "Epoch_8",
          "Epoch_9",
          "Epoch_10",
          "Epoch_11",
          "Epoch_12",
          "Epoch_13",
          "Epoch_14",
          "Epoch_15",
          "Epoch_16",
          "Epoch_17",
          "Epoch_18",
          "Epoch_19",
          "Epoch_20"
         ],
         "xaxis": "x",
         "y": [
          1.0512422526569,
          0.7273955299401842,
          0.6705788934408728,
          0.6355121100126807,
          0.6082512067833434,
          0.5853243775840508,
          0.565576980807888,
          0.5481405542222167,
          0.5327024161815643,
          0.5203996028727306,
          0.5073587848687731,
          0.49643460646875376,
          0.487200616646423,
          0.4785808470965957,
          0.4702556541225295,
          0.46275581467126226,
          0.4556988843722638,
          0.4493317171963039,
          0.4427280684015644,
          0.4356507512170877
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Combination=SGD-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>",
         "legendgroup": "SGD-NLL",
         "line": {
          "color": "#9467BD",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "SGD-NLL",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "Epoch_1",
          "Epoch_2",
          "Epoch_3",
          "Epoch_4",
          "Epoch_5",
          "Epoch_6",
          "Epoch_7",
          "Epoch_8",
          "Epoch_9",
          "Epoch_10",
          "Epoch_11",
          "Epoch_12",
          "Epoch_13",
          "Epoch_14",
          "Epoch_15",
          "Epoch_16",
          "Epoch_17",
          "Epoch_18",
          "Epoch_19",
          "Epoch_20"
         ],
         "xaxis": "x",
         "y": [
          2.3021860015926077,
          2.3016213287931007,
          2.3010558980360214,
          2.3004841291065663,
          2.2999145074693885,
          2.2993400813674114,
          2.2987705985111977,
          2.2981988982096917,
          2.297622959751056,
          2.2970440707989592,
          2.296466010465805,
          2.2958798169581365,
          2.2952950071932663,
          2.2947003383880484,
          2.2941039116906206,
          2.2935039956432415,
          2.292888142660991,
          2.292272166148432,
          2.2916409781238416,
          2.2910027326042974
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Combination"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "title": {
         "text": "Optimizer Experiment"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Training Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "<b>Log</b> Loss"
         },
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"62443f1a-8700-4e6d-a6a1-e760c416054c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"62443f1a-8700-4e6d-a6a1-e760c416054c\")) {                    Plotly.newPlot(                        \"62443f1a-8700-4e6d-a6a1-e760c416054c\",                        [{\"hovertemplate\":\"Combination=Adadelta-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>\",\"legendgroup\":\"Adadelta-NLL\",\"line\":{\"color\":\"#1F77B4\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"Adadelta-NLL\",\"orientation\":\"v\",\"showlegend\":true,\"type\":\"scatter\",\"x\":[\"Epoch_1\",\"Epoch_2\",\"Epoch_3\",\"Epoch_4\",\"Epoch_5\",\"Epoch_6\",\"Epoch_7\",\"Epoch_8\",\"Epoch_9\",\"Epoch_10\",\"Epoch_11\",\"Epoch_12\",\"Epoch_13\",\"Epoch_14\",\"Epoch_15\",\"Epoch_16\",\"Epoch_17\",\"Epoch_18\",\"Epoch_19\",\"Epoch_20\"],\"xaxis\":\"x\",\"y\":[2.304752920228027,2.304639879320222,2.3045193213643804,2.3044079300691322,2.3042914572555118,2.304179283093288,2.3040664638283412,2.3039517316228544,2.303842895829093,2.3037304319044165,2.303625842401468,2.303512620519219,2.303403151823259,2.3032860537327684,2.303175117415406,2.3030692870174643,2.302957877929785,2.3028486964545016,2.3027388475088677,2.302630601915469],\"yaxis\":\"y\"},{\"hovertemplate\":\"Combination=Adagrad-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>\",\"legendgroup\":\"Adagrad-NLL\",\"line\":{\"color\":\"#FF7F0E\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"Adagrad-NLL\",\"orientation\":\"v\",\"showlegend\":true,\"type\":\"scatter\",\"x\":[\"Epoch_1\",\"Epoch_2\",\"Epoch_3\",\"Epoch_4\",\"Epoch_5\",\"Epoch_6\",\"Epoch_7\",\"Epoch_8\",\"Epoch_9\",\"Epoch_10\",\"Epoch_11\",\"Epoch_12\",\"Epoch_13\",\"Epoch_14\",\"Epoch_15\",\"Epoch_16\",\"Epoch_17\",\"Epoch_18\",\"Epoch_19\",\"Epoch_20\"],\"xaxis\":\"x\",\"y\":[2.2627081367761086,2.180890495589039,2.085980851512982,1.9867335128377495,1.8869204017907573,1.7906770662966567,1.701089120622891,1.6205009082232966,1.5489305916117198,1.4860463322861108,1.4309364392050803,1.382832447603059,1.341013641753939,1.3047008361897743,1.2727850446823055,1.2445609335706178,1.2191897495977406,1.1963536009859683,1.1760137963142476,1.157999258051549],\"yaxis\":\"y\"},{\"hovertemplate\":\"Combination=Adam-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>\",\"legendgroup\":\"Adam-NLL\",\"line\":{\"color\":\"#2CA02C\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"Adam-NLL\",\"orientation\":\"v\",\"showlegend\":true,\"type\":\"scatter\",\"x\":[\"Epoch_1\",\"Epoch_2\",\"Epoch_3\",\"Epoch_4\",\"Epoch_5\",\"Epoch_6\",\"Epoch_7\",\"Epoch_8\",\"Epoch_9\",\"Epoch_10\",\"Epoch_11\",\"Epoch_12\",\"Epoch_13\",\"Epoch_14\",\"Epoch_15\",\"Epoch_16\",\"Epoch_17\",\"Epoch_18\",\"Epoch_19\",\"Epoch_20\"],\"xaxis\":\"x\",\"y\":[1.3135513071058147,0.753661917979275,0.6753041978711004,0.628896613492132,0.5964356950605347,0.5712236427803283,0.5509112968500743,0.5344106643947203,0.5194504688035196,0.5050828069893282,0.49453629791609516,0.48326981677683684,0.4736171671068236,0.46541435879939147,0.456563083284191,0.45129557656072605,0.44339002411502765,0.4377056162621675,0.4310129442448809,0.4267545803142255],\"yaxis\":\"y\"},{\"hovertemplate\":\"Combination=RMSprop-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>\",\"legendgroup\":\"RMSprop-NLL\",\"line\":{\"color\":\"#D62728\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"RMSprop-NLL\",\"orientation\":\"v\",\"showlegend\":true,\"type\":\"scatter\",\"x\":[\"Epoch_1\",\"Epoch_2\",\"Epoch_3\",\"Epoch_4\",\"Epoch_5\",\"Epoch_6\",\"Epoch_7\",\"Epoch_8\",\"Epoch_9\",\"Epoch_10\",\"Epoch_11\",\"Epoch_12\",\"Epoch_13\",\"Epoch_14\",\"Epoch_15\",\"Epoch_16\",\"Epoch_17\",\"Epoch_18\",\"Epoch_19\",\"Epoch_20\"],\"xaxis\":\"x\",\"y\":[1.0512422526569,0.7273955299401842,0.6705788934408728,0.6355121100126807,0.6082512067833434,0.5853243775840508,0.565576980807888,0.5481405542222167,0.5327024161815643,0.5203996028727306,0.5073587848687731,0.49643460646875376,0.487200616646423,0.4785808470965957,0.4702556541225295,0.46275581467126226,0.4556988843722638,0.4493317171963039,0.4427280684015644,0.4356507512170877],\"yaxis\":\"y\"},{\"hovertemplate\":\"Combination=SGD-NLL<br>Training Epoch=%{x}<br><b>Log</b> Loss=%{y}<extra></extra>\",\"legendgroup\":\"SGD-NLL\",\"line\":{\"color\":\"#9467BD\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"SGD-NLL\",\"orientation\":\"v\",\"showlegend\":true,\"type\":\"scatter\",\"x\":[\"Epoch_1\",\"Epoch_2\",\"Epoch_3\",\"Epoch_4\",\"Epoch_5\",\"Epoch_6\",\"Epoch_7\",\"Epoch_8\",\"Epoch_9\",\"Epoch_10\",\"Epoch_11\",\"Epoch_12\",\"Epoch_13\",\"Epoch_14\",\"Epoch_15\",\"Epoch_16\",\"Epoch_17\",\"Epoch_18\",\"Epoch_19\",\"Epoch_20\"],\"xaxis\":\"x\",\"y\":[2.3021860015926077,2.3016213287931007,2.3010558980360214,2.3004841291065663,2.2999145074693885,2.2993400813674114,2.2987705985111977,2.2981988982096917,2.297622959751056,2.2970440707989592,2.296466010465805,2.2958798169581365,2.2952950071932663,2.2947003383880484,2.2941039116906206,2.2935039956432415,2.292888142660991,2.292272166148432,2.2916409781238416,2.2910027326042974],\"yaxis\":\"y\"}],                        {\"legend\":{\"title\":{\"text\":\"Combination\"},\"tracegroupgap\":0},\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"title\":{\"text\":\"Optimizer Experiment\"},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Training Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Log</b> Loss\"},\"type\":\"log\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('62443f1a-8700-4e6d-a6a1-e760c416054c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(\n",
    "    df_optimizers,\n",
    "    title='Optimizer Experiment',\n",
    "    labels={\n",
    "        'index': 'Training Epoch',\n",
    "        'value': '<b>Log</b> Loss',\n",
    "        'variable': 'Combination',\n",
    "    },\n",
    "    template='none',\n",
    "    log_y=True,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\"\"\"\n",
    "The experiment shows, that SGD unfortunately is the worst optimizer\n",
    "for this data. That explains the linear slope in Task 1.\n",
    "Adam and RMSprop do a much better job with RMSprop doing a slightly\n",
    "better job (this changes after each iteration!). \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel-Size & Epochs Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def train_model_2(\n",
    "    num_epochs: int, \n",
    "    kernel_size: int, \n",
    "    padding: int,\n",
    "    mini_batch_size = MINI_BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    criterion=nn.NLLLoss(),\n",
    "):\n",
    "    overall_losses = []\n",
    "    train_epoch_losses = []\n",
    "    \n",
    "    fashion_mnist_train_dataloader = torch.utils.data.DataLoader(TRAIN_DATA, batch_size=mini_batch_size, shuffle=True)\n",
    "    \n",
    "    model = FashionMnist(kernel_size, padding)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.RMSprop(params=model.parameters(), lr=lr)\n",
    "    criterion.to(device)\n",
    "\n",
    "    # Adjust LR\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.1, patience=3, threshold=0.0001, threshold_mode='abs',)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_mini_batch_losses = []\n",
    "\n",
    "        for _, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(images)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Must be after loss!\n",
    "            scheduler.step(loss)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "        train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "        print(f'Epoch: {epoch} train-loss: {train_epoch_loss}')\n",
    "\n",
    "        train_epoch_losses.append(train_epoch_loss)\n",
    "    overall_losses.append(train_epoch_losses)\n",
    "    print(overall_losses)\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    return model, overall_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "Epoch: 0 train-loss: 1.4335088745109055\n",
      "Epoch: 1 train-loss: 1.330315076466054\n",
      "Epoch: 2 train-loss: 1.3300310856243696\n",
      "Epoch: 3 train-loss: 1.3298323375583967\n",
      "Epoch: 4 train-loss: 1.329515532898242\n",
      "Epoch: 5 train-loss: 1.3292913106458781\n",
      "Epoch: 6 train-loss: 1.3290746712735466\n",
      "Epoch: 7 train-loss: 1.3287921145018229\n",
      "[[1.4335088745109055, 1.330315076466054, 1.3300310856243696, 1.3298323375583967, 1.329515532898242, 1.3292913106458781, 1.3290746712735466, 1.3287921145018229]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 93.7825 seconds.\n",
      "Kernel: 4x4\n",
      "Epoch: 8\n",
      "Accuracy: 0.631\n",
      "F1-score: 0.6062822785552365\n",
      "\n",
      "\n",
      "[0.631]\n",
      "[0.6063]\n",
      "4\n",
      "16\n",
      "Epoch: 0 train-loss: 1.7227751657144348\n",
      "Epoch: 1 train-loss: 1.6883789377171856\n",
      "Epoch: 2 train-loss: 1.6880094374674979\n",
      "Epoch: 3 train-loss: 1.6876796209481733\n",
      "Epoch: 4 train-loss: 1.6872972168647913\n",
      "Epoch: 5 train-loss: 1.6869668752145666\n",
      "Epoch: 6 train-loss: 1.6866342640126437\n",
      "Epoch: 7 train-loss: 1.686276013917252\n",
      "Epoch: 8 train-loss: 1.6858929520222679\n",
      "Epoch: 9 train-loss: 1.6855977364440462\n",
      "Epoch: 10 train-loss: 1.6852461905367593\n",
      "Epoch: 11 train-loss: 1.6849322570666576\n",
      "Epoch: 12 train-loss: 1.6845510473637693\n",
      "Epoch: 13 train-loss: 1.6842564878179067\n",
      "Epoch: 14 train-loss: 1.6839158507044127\n",
      "Epoch: 15 train-loss: 1.68358500476585\n",
      "[[1.7227751657144348, 1.6883789377171856, 1.6880094374674979, 1.6876796209481733, 1.6872972168647913, 1.6869668752145666, 1.6866342640126437, 1.686276013917252, 1.6858929520222679, 1.6855977364440462, 1.6852461905367593, 1.6849322570666576, 1.6845510473637693, 1.6842564878179067, 1.6839158507044127, 1.68358500476585]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 187.8449 seconds.\n",
      "Kernel: 4x4\n",
      "Epoch: 16\n",
      "Accuracy: 0.4491\n",
      "F1-score: 0.368976824041583\n",
      "\n",
      "\n",
      "[0.631, 0.4491]\n",
      "[0.6063, 0.369]\n",
      "4\n",
      "32\n",
      "Epoch: 0 train-loss: 2.1376166343688965\n",
      "Epoch: 1 train-loss: 2.1315447592786128\n",
      "Epoch: 2 train-loss: 2.131411716119567\n",
      "Epoch: 3 train-loss: 2.1312818308628954\n",
      "Epoch: 4 train-loss: 2.1311332833792354\n",
      "Epoch: 5 train-loss: 2.1309798190842812\n",
      "Epoch: 6 train-loss: 2.1308451532555033\n",
      "Epoch: 7 train-loss: 2.130702874807915\n",
      "Epoch: 8 train-loss: 2.130590917204997\n",
      "Epoch: 9 train-loss: 2.130426441936859\n",
      "Epoch: 10 train-loss: 2.1302928350119195\n",
      "Epoch: 11 train-loss: 2.1301711383404762\n",
      "Epoch: 12 train-loss: 2.1300272509487455\n",
      "Epoch: 13 train-loss: 2.1298838485278555\n",
      "Epoch: 14 train-loss: 2.1297501043470177\n",
      "Epoch: 15 train-loss: 2.1296051799107207\n",
      "Epoch: 16 train-loss: 2.129462029634\n",
      "Epoch: 17 train-loss: 2.129334536188447\n",
      "Epoch: 18 train-loss: 2.1291845475178537\n",
      "Epoch: 19 train-loss: 2.129070909292713\n",
      "Epoch: 20 train-loss: 2.1289082188596096\n",
      "Epoch: 21 train-loss: 2.1287625146064677\n",
      "Epoch: 22 train-loss: 2.1286309014505416\n",
      "Epoch: 23 train-loss: 2.1284893890942085\n",
      "Epoch: 24 train-loss: 2.1283485604755916\n",
      "Epoch: 25 train-loss: 2.1282203161894384\n",
      "Epoch: 26 train-loss: 2.128085189282513\n",
      "Epoch: 27 train-loss: 2.127934685648123\n",
      "Epoch: 28 train-loss: 2.1277995907675735\n",
      "Epoch: 29 train-loss: 2.1276617949959564\n",
      "Epoch: 30 train-loss: 2.1275194143689773\n",
      "Epoch: 31 train-loss: 2.1273787448655312\n",
      "[[2.1376166343688965, 2.1315447592786128, 2.131411716119567, 2.1312818308628954, 2.1311332833792354, 2.1309798190842812, 2.1308451532555033, 2.130702874807915, 2.130590917204997, 2.130426441936859, 2.1302928350119195, 2.1301711383404762, 2.1300272509487455, 2.1298838485278555, 2.1297501043470177, 2.1296051799107207, 2.129462029634, 2.129334536188447, 2.1291845475178537, 2.129070909292713, 2.1289082188596096, 2.1287625146064677, 2.1286309014505416, 2.1284893890942085, 2.1283485604755916, 2.1282203161894384, 2.128085189282513, 2.127934685648123, 2.1277995907675735, 2.1276617949959564, 2.1275194143689773, 2.1273787448655312]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 378.9453 seconds.\n",
      "Kernel: 4x4\n",
      "Epoch: 32\n",
      "Accuracy: 0.3148\n",
      "F1-score: 0.20212292794215603\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148]\n",
      "[0.6063, 0.369, 0.2021]\n",
      "4\n",
      "64\n",
      "Epoch: 0 train-loss: 1.6979172336521433\n",
      "Epoch: 1 train-loss: 1.650510247328134\n",
      "Epoch: 2 train-loss: 1.6502016154941974\n",
      "Epoch: 3 train-loss: 1.6499148368327095\n",
      "Epoch: 4 train-loss: 1.649640998352311\n",
      "Epoch: 5 train-loss: 1.6493801145411249\n",
      "Epoch: 6 train-loss: 1.6490915487570041\n",
      "Epoch: 7 train-loss: 1.6487808362253185\n",
      "Epoch: 8 train-loss: 1.6485245479449535\n",
      "Epoch: 9 train-loss: 1.6482670490167288\n",
      "Epoch: 10 train-loss: 1.6479607817969089\n",
      "Epoch: 11 train-loss: 1.6476861512991412\n",
      "Epoch: 12 train-loss: 1.6474230299626331\n",
      "Epoch: 13 train-loss: 1.6471588098164052\n",
      "Epoch: 14 train-loss: 1.6468603839752263\n",
      "Epoch: 15 train-loss: 1.6465281540396879\n",
      "Epoch: 16 train-loss: 1.6462665740360838\n",
      "Epoch: 17 train-loss: 1.6460181528062963\n",
      "Epoch: 18 train-loss: 1.6457213140499871\n",
      "Epoch: 19 train-loss: 1.6454398797264993\n",
      "Epoch: 20 train-loss: 1.6452112416468703\n",
      "Epoch: 21 train-loss: 1.644879187093869\n",
      "Epoch: 22 train-loss: 1.6446400560549836\n",
      "Epoch: 23 train-loss: 1.6442991558676843\n",
      "Epoch: 24 train-loss: 1.6440673499727554\n",
      "Epoch: 25 train-loss: 1.6437839414519289\n",
      "Epoch: 26 train-loss: 1.6435110807927178\n",
      "Epoch: 27 train-loss: 1.643253722678878\n",
      "Epoch: 28 train-loss: 1.642979068034239\n",
      "Epoch: 29 train-loss: 1.642680066226642\n",
      "Epoch: 30 train-loss: 1.6424142063807832\n",
      "Epoch: 31 train-loss: 1.6421185958105873\n",
      "Epoch: 32 train-loss: 1.6418523618153162\n",
      "Epoch: 33 train-loss: 1.6415793245026806\n",
      "Epoch: 34 train-loss: 1.6413146460742585\n",
      "Epoch: 35 train-loss: 1.6410392759197048\n",
      "Epoch: 36 train-loss: 1.6407285138233891\n",
      "Epoch: 37 train-loss: 1.6404607112982126\n",
      "Epoch: 38 train-loss: 1.6401775175574491\n",
      "Epoch: 39 train-loss: 1.6399347253445624\n",
      "Epoch: 40 train-loss: 1.6396487493759024\n",
      "Epoch: 41 train-loss: 1.639377530703921\n",
      "Epoch: 42 train-loss: 1.639110945435221\n",
      "Epoch: 43 train-loss: 1.6388294676473654\n",
      "Epoch: 44 train-loss: 1.6385623201378372\n",
      "Epoch: 45 train-loss: 1.6382735810046003\n",
      "Epoch: 46 train-loss: 1.6380376625162707\n",
      "Epoch: 47 train-loss: 1.637755783890356\n",
      "Epoch: 48 train-loss: 1.6374290769796636\n",
      "Epoch: 49 train-loss: 1.637156623767129\n",
      "Epoch: 50 train-loss: 1.6368754982694125\n",
      "Epoch: 51 train-loss: 1.6366478420778123\n",
      "Epoch: 52 train-loss: 1.6363629735609106\n",
      "Epoch: 53 train-loss: 1.636072227187248\n",
      "Epoch: 54 train-loss: 1.6358089525816537\n",
      "Epoch: 55 train-loss: 1.635539433595214\n",
      "Epoch: 56 train-loss: 1.6352804782294006\n",
      "Epoch: 57 train-loss: 1.6349916722474576\n",
      "Epoch: 58 train-loss: 1.6347285981879813\n",
      "Epoch: 59 train-loss: 1.6344201163188228\n",
      "Epoch: 60 train-loss: 1.6342017332882262\n",
      "Epoch: 61 train-loss: 1.633916089529676\n",
      "Epoch: 62 train-loss: 1.633624406257418\n",
      "Epoch: 63 train-loss: 1.633373511371328\n",
      "[[1.6979172336521433, 1.650510247328134, 1.6502016154941974, 1.6499148368327095, 1.649640998352311, 1.6493801145411249, 1.6490915487570041, 1.6487808362253185, 1.6485245479449535, 1.6482670490167288, 1.6479607817969089, 1.6476861512991412, 1.6474230299626331, 1.6471588098164052, 1.6468603839752263, 1.6465281540396879, 1.6462665740360838, 1.6460181528062963, 1.6457213140499871, 1.6454398797264993, 1.6452112416468703, 1.644879187093869, 1.6446400560549836, 1.6442991558676843, 1.6440673499727554, 1.6437839414519289, 1.6435110807927178, 1.643253722678878, 1.642979068034239, 1.642680066226642, 1.6424142063807832, 1.6421185958105873, 1.6418523618153162, 1.6415793245026806, 1.6413146460742585, 1.6410392759197048, 1.6407285138233891, 1.6404607112982126, 1.6401775175574491, 1.6399347253445624, 1.6396487493759024, 1.639377530703921, 1.639110945435221, 1.6388294676473654, 1.6385623201378372, 1.6382735810046003, 1.6380376625162707, 1.637755783890356, 1.6374290769796636, 1.637156623767129, 1.6368754982694125, 1.6366478420778123, 1.6363629735609106, 1.636072227187248, 1.6358089525816537, 1.635539433595214, 1.6352804782294006, 1.6349916722474576, 1.6347285981879813, 1.6344201163188228, 1.6342017332882262, 1.633916089529676, 1.633624406257418, 1.633373511371328]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 760.1919 seconds.\n",
      "Kernel: 4x4\n",
      "Epoch: 64\n",
      "Accuracy: 0.5873\n",
      "F1-score: 0.5253801879376558\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873]\n",
      "[0.6063, 0.369, 0.2021, 0.5254]\n",
      "6\n",
      "8\n",
      "Epoch: 0 train-loss: 1.5339394075784094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train-loss: 1.453384769496633\n",
      "Epoch: 2 train-loss: 1.453031746309195\n",
      "Epoch: 3 train-loss: 1.4527044695323463\n",
      "Epoch: 4 train-loss: 1.452350807342448\n",
      "Epoch: 5 train-loss: 1.4519666115612364\n",
      "Epoch: 6 train-loss: 1.451645673210941\n",
      "Epoch: 7 train-loss: 1.4512520151605992\n",
      "[[1.5339394075784094, 1.453384769496633, 1.453031746309195, 1.4527044695323463, 1.452350807342448, 1.4519666115612364, 1.451645673210941, 1.4512520151605992]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 130.1738 seconds.\n",
      "Kernel: 6x6\n",
      "Epoch: 8\n",
      "Accuracy: 0.5816\n",
      "F1-score: 0.5266201664962257\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266]\n",
      "6\n",
      "16\n",
      "Epoch: 0 train-loss: 1.2739526821352016\n",
      "Epoch: 1 train-loss: 1.1898243002800037\n",
      "Epoch: 2 train-loss: 1.1895553168457453\n",
      "Epoch: 3 train-loss: 1.189162584510185\n",
      "Epoch: 4 train-loss: 1.18886306367195\n",
      "Epoch: 5 train-loss: 1.1885134932328898\n",
      "Epoch: 6 train-loss: 1.188228601840005\n",
      "Epoch: 7 train-loss: 1.1879341243935038\n",
      "Epoch: 8 train-loss: 1.1875721028110366\n",
      "Epoch: 9 train-loss: 1.1872516346892823\n",
      "Epoch: 10 train-loss: 1.1869433772589353\n",
      "Epoch: 11 train-loss: 1.1866232416014681\n",
      "Epoch: 12 train-loss: 1.186287242974808\n",
      "Epoch: 13 train-loss: 1.1860158967056762\n",
      "Epoch: 14 train-loss: 1.185661216026176\n",
      "Epoch: 15 train-loss: 1.1854258672769136\n",
      "[[1.2739526821352016, 1.1898243002800037, 1.1895553168457453, 1.189162584510185, 1.18886306367195, 1.1885134932328898, 1.188228601840005, 1.1879341243935038, 1.1875721028110366, 1.1872516346892823, 1.1869433772589353, 1.1866232416014681, 1.186287242974808, 1.1860158967056762, 1.185661216026176, 1.1854258672769136]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 216.3092 seconds.\n",
      "Kernel: 6x6\n",
      "Epoch: 16\n",
      "Accuracy: 0.66\n",
      "F1-score: 0.6315213358805986\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315]\n",
      "6\n",
      "32\n",
      "Epoch: 0 train-loss: 1.6827771935635791\n",
      "Epoch: 1 train-loss: 1.6421280461333707\n",
      "Epoch: 2 train-loss: 1.6417643002101354\n",
      "Epoch: 3 train-loss: 1.6414686626971149\n",
      "Epoch: 4 train-loss: 1.641080943760333\n",
      "Epoch: 5 train-loss: 1.6407203877658478\n",
      "Epoch: 6 train-loss: 1.640379193749255\n",
      "Epoch: 7 train-loss: 1.6399810148963034\n",
      "Epoch: 8 train-loss: 1.6396241688779167\n",
      "Epoch: 9 train-loss: 1.639268281363221\n",
      "Epoch: 10 train-loss: 1.6389323450100701\n",
      "Epoch: 11 train-loss: 1.638630163695004\n",
      "Epoch: 12 train-loss: 1.6382728616820215\n",
      "Epoch: 13 train-loss: 1.637929130973084\n",
      "Epoch: 14 train-loss: 1.6375310385405129\n",
      "Epoch: 15 train-loss: 1.6371896831211505\n",
      "Epoch: 16 train-loss: 1.6368624947981032\n",
      "Epoch: 17 train-loss: 1.6365477939658581\n",
      "Epoch: 18 train-loss: 1.6361654214004973\n",
      "Epoch: 19 train-loss: 1.6358234231660107\n",
      "Epoch: 20 train-loss: 1.6355191550529333\n",
      "Epoch: 21 train-loss: 1.635137485796963\n",
      "Epoch: 22 train-loss: 1.6347870026061784\n",
      "Epoch: 23 train-loss: 1.634420962221841\n",
      "Epoch: 24 train-loss: 1.6341044953637032\n",
      "Epoch: 25 train-loss: 1.6337430779613666\n",
      "Epoch: 26 train-loss: 1.633452486381856\n",
      "Epoch: 27 train-loss: 1.6330195263758907\n",
      "Epoch: 28 train-loss: 1.6327573142326208\n",
      "Epoch: 29 train-loss: 1.632414802051048\n",
      "Epoch: 30 train-loss: 1.6320579001135918\n",
      "Epoch: 31 train-loss: 1.6317381957954944\n",
      "[[1.6827771935635791, 1.6421280461333707, 1.6417643002101354, 1.6414686626971149, 1.641080943760333, 1.6407203877658478, 1.640379193749255, 1.6399810148963034, 1.6396241688779167, 1.639268281363221, 1.6389323450100701, 1.638630163695004, 1.6382728616820215, 1.637929130973084, 1.6375310385405129, 1.6371896831211505, 1.6368624947981032, 1.6365477939658581, 1.6361654214004973, 1.6358234231660107, 1.6355191550529333, 1.635137485796963, 1.6347870026061784, 1.634420962221841, 1.6341044953637032, 1.6337430779613666, 1.633452486381856, 1.6330195263758907, 1.6327573142326208, 1.632414802051048, 1.6320579001135918, 1.6317381957954944]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 430.8987 seconds.\n",
      "Kernel: 6x6\n",
      "Epoch: 32\n",
      "Accuracy: 0.4613\n",
      "F1-score: 0.4085984651680942\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66, 0.4613]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315, 0.4086]\n",
      "6\n",
      "64\n",
      "Epoch: 0 train-loss: 1.5823274573791763\n",
      "Epoch: 1 train-loss: 1.529588194035772\n",
      "Epoch: 2 train-loss: 1.5292487113968904\n",
      "Epoch: 3 train-loss: 1.52894678044675\n",
      "Epoch: 4 train-loss: 1.528619912641643\n",
      "Epoch: 5 train-loss: 1.528276360111196\n",
      "Epoch: 6 train-loss: 1.5279569376760453\n",
      "Epoch: 7 train-loss: 1.527557107431294\n",
      "Epoch: 8 train-loss: 1.527273350941347\n",
      "Epoch: 9 train-loss: 1.5269741895102233\n",
      "Epoch: 10 train-loss: 1.5265843451404368\n",
      "Epoch: 11 train-loss: 1.5262434848590192\n",
      "Epoch: 12 train-loss: 1.5259347333074378\n",
      "Epoch: 13 train-loss: 1.5256135509466566\n",
      "Epoch: 14 train-loss: 1.525261512951556\n",
      "Epoch: 15 train-loss: 1.5249685577746392\n",
      "Epoch: 16 train-loss: 1.5245959636753301\n",
      "Epoch: 17 train-loss: 1.524299191767727\n",
      "Epoch: 18 train-loss: 1.5239142657343003\n",
      "Epoch: 19 train-loss: 1.5236134346105905\n",
      "Epoch: 20 train-loss: 1.5232815798411745\n",
      "Epoch: 21 train-loss: 1.5229668436782446\n",
      "Epoch: 22 train-loss: 1.5226384200521115\n",
      "Epoch: 23 train-loss: 1.5222768417553607\n",
      "Epoch: 24 train-loss: 1.5219711771906057\n",
      "Epoch: 25 train-loss: 1.5216541592754536\n",
      "Epoch: 26 train-loss: 1.5212574439770632\n",
      "Epoch: 27 train-loss: 1.520982907270826\n",
      "Epoch: 28 train-loss: 1.5206611774115166\n",
      "Epoch: 29 train-loss: 1.520353969734615\n",
      "Epoch: 30 train-loss: 1.5200244325564614\n",
      "Epoch: 31 train-loss: 1.5197315798131132\n",
      "Epoch: 32 train-loss: 1.519391565434714\n",
      "Epoch: 33 train-loss: 1.5190566679053723\n",
      "Epoch: 34 train-loss: 1.5187507860187783\n",
      "Epoch: 35 train-loss: 1.5184088759839154\n",
      "Epoch: 36 train-loss: 1.5180468635518414\n",
      "Epoch: 37 train-loss: 1.5177833436648729\n",
      "Epoch: 38 train-loss: 1.5174173902092711\n",
      "Epoch: 39 train-loss: 1.5171004549018356\n",
      "Epoch: 40 train-loss: 1.5167876997990395\n",
      "Epoch: 41 train-loss: 1.5164718612679031\n",
      "Epoch: 42 train-loss: 1.516149014552265\n",
      "Epoch: 43 train-loss: 1.5158618958011618\n",
      "Epoch: 44 train-loss: 1.5154848764700168\n",
      "Epoch: 45 train-loss: 1.5151611421662352\n",
      "Epoch: 46 train-loss: 1.514845950262887\n",
      "Epoch: 47 train-loss: 1.5145409961244953\n",
      "Epoch: 48 train-loss: 1.5141887563123886\n",
      "Epoch: 49 train-loss: 1.5139296423397592\n",
      "Epoch: 50 train-loss: 1.5136158212161521\n",
      "Epoch: 51 train-loss: 1.5133111110882465\n",
      "Epoch: 52 train-loss: 1.512967529581554\n",
      "Epoch: 53 train-loss: 1.5125935397930999\n",
      "Epoch: 54 train-loss: 1.5123251844316656\n",
      "Epoch: 55 train-loss: 1.5119899966315167\n",
      "Epoch: 56 train-loss: 1.5116518026730146\n",
      "Epoch: 57 train-loss: 1.5113340194291398\n",
      "Epoch: 58 train-loss: 1.5110407546639189\n",
      "Epoch: 59 train-loss: 1.510742356528097\n",
      "Epoch: 60 train-loss: 1.5104162756568078\n",
      "Epoch: 61 train-loss: 1.5100942334132408\n",
      "Epoch: 62 train-loss: 1.5098136022909363\n",
      "Epoch: 63 train-loss: 1.5094809049228106\n",
      "[[1.5823274573791763, 1.529588194035772, 1.5292487113968904, 1.52894678044675, 1.528619912641643, 1.528276360111196, 1.5279569376760453, 1.527557107431294, 1.527273350941347, 1.5269741895102233, 1.5265843451404368, 1.5262434848590192, 1.5259347333074378, 1.5256135509466566, 1.525261512951556, 1.5249685577746392, 1.5245959636753301, 1.524299191767727, 1.5239142657343003, 1.5236134346105905, 1.5232815798411745, 1.5229668436782446, 1.5226384200521115, 1.5222768417553607, 1.5219711771906057, 1.5216541592754536, 1.5212574439770632, 1.520982907270826, 1.5206611774115166, 1.520353969734615, 1.5200244325564614, 1.5197315798131132, 1.519391565434714, 1.5190566679053723, 1.5187507860187783, 1.5184088759839154, 1.5180468635518414, 1.5177833436648729, 1.5174173902092711, 1.5171004549018356, 1.5167876997990395, 1.5164718612679031, 1.516149014552265, 1.5158618958011618, 1.5154848764700168, 1.5151611421662352, 1.514845950262887, 1.5145409961244953, 1.5141887563123886, 1.5139296423397592, 1.5136158212161521, 1.5133111110882465, 1.512967529581554, 1.5125935397930999, 1.5123251844316656, 1.5119899966315167, 1.5116518026730146, 1.5113340194291398, 1.5110407546639189, 1.510742356528097, 1.5104162756568078, 1.5100942334132408, 1.5098136022909363, 1.5094809049228106]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 892.3523 seconds.\n",
      "Kernel: 6x6\n",
      "Epoch: 64\n",
      "Accuracy: 0.5785\n",
      "F1-score: 0.5230071925547263\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66, 0.4613, 0.5785]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315, 0.4086, 0.523]\n",
      "8\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train-loss: 1.3879313654482746\n",
      "Epoch: 1 train-loss: 1.3336074037084193\n",
      "Epoch: 2 train-loss: 1.333169617632559\n",
      "Epoch: 3 train-loss: 1.332697814461519\n",
      "Epoch: 4 train-loss: 1.3322999614642372\n",
      "Epoch: 5 train-loss: 1.3319007153195868\n",
      "Epoch: 6 train-loss: 1.3314541740966503\n",
      "Epoch: 7 train-loss: 1.3310188011828261\n",
      "[[1.3879313654482746, 1.3336074037084193, 1.333169617632559, 1.332697814461519, 1.3322999614642372, 1.3319007153195868, 1.3314541740966503, 1.3310188011828261]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 124.1496 seconds.\n",
      "Kernel: 8x8\n",
      "Epoch: 8\n",
      "Accuracy: 0.5985\n",
      "F1-score: 0.533377082677139\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66, 0.4613, 0.5785, 0.5985]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315, 0.4086, 0.523, 0.5334]\n",
      "8\n",
      "16\n",
      "Epoch: 0 train-loss: 1.4938130114378452\n",
      "Epoch: 1 train-loss: 1.444620601403942\n",
      "Epoch: 2 train-loss: 1.4440846311003923\n",
      "Epoch: 3 train-loss: 1.4435255901137394\n",
      "Epoch: 4 train-loss: 1.4429504884077287\n",
      "Epoch: 5 train-loss: 1.4425189505253773\n",
      "Epoch: 6 train-loss: 1.441966845028436\n",
      "Epoch: 7 train-loss: 1.4414594109887\n",
      "Epoch: 8 train-loss: 1.4409384834232615\n",
      "Epoch: 9 train-loss: 1.4404973198355897\n",
      "Epoch: 10 train-loss: 1.4398466768041094\n",
      "Epoch: 11 train-loss: 1.4394226102178285\n",
      "Epoch: 12 train-loss: 1.4389716480840753\n",
      "Epoch: 13 train-loss: 1.4384806834812611\n",
      "Epoch: 14 train-loss: 1.4380058416171368\n",
      "Epoch: 15 train-loss: 1.4375199725124628\n",
      "[[1.4938130114378452, 1.444620601403942, 1.4440846311003923, 1.4435255901137394, 1.4429504884077287, 1.4425189505253773, 1.441966845028436, 1.4414594109887, 1.4409384834232615, 1.4404973198355897, 1.4398466768041094, 1.4394226102178285, 1.4389716480840753, 1.4384806834812611, 1.4380058416171368, 1.4375199725124628]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 246.5721 seconds.\n",
      "Kernel: 8x8\n",
      "Epoch: 16\n",
      "Accuracy: 0.546\n",
      "F1-score: 0.48152014649396185\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66, 0.4613, 0.5785, 0.5985, 0.546]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315, 0.4086, 0.523, 0.5334, 0.4815]\n",
      "8\n",
      "32\n",
      "Epoch: 0 train-loss: 1.392573175653974\n",
      "Epoch: 1 train-loss: 1.335429245220827\n",
      "Epoch: 2 train-loss: 1.3349396206422655\n",
      "Epoch: 3 train-loss: 1.3345284047665626\n",
      "Epoch: 4 train-loss: 1.334141177409239\n",
      "Epoch: 5 train-loss: 1.3336659580913943\n",
      "Epoch: 6 train-loss: 1.3331648065591417\n",
      "Epoch: 7 train-loss: 1.332785119125838\n",
      "Epoch: 8 train-loss: 1.3322912002168994\n",
      "Epoch: 9 train-loss: 1.3318587798299566\n",
      "Epoch: 10 train-loss: 1.3314267747691955\n",
      "Epoch: 11 train-loss: 1.3310293271851692\n",
      "Epoch: 12 train-loss: 1.3305529856732659\n",
      "Epoch: 13 train-loss: 1.3302075382488876\n",
      "Epoch: 14 train-loss: 1.3297732407604452\n",
      "Epoch: 15 train-loss: 1.329337861746359\n",
      "Epoch: 16 train-loss: 1.3289103279235774\n",
      "Epoch: 17 train-loss: 1.328510975786872\n",
      "Epoch: 18 train-loss: 1.3281544403735\n",
      "Epoch: 19 train-loss: 1.3277705742606223\n",
      "Epoch: 20 train-loss: 1.327350713805095\n",
      "Epoch: 21 train-loss: 1.3269293989453996\n",
      "Epoch: 22 train-loss: 1.326589594771867\n",
      "Epoch: 23 train-loss: 1.3261787843094197\n",
      "Epoch: 24 train-loss: 1.3257487544627078\n",
      "Epoch: 25 train-loss: 1.325369930470676\n",
      "Epoch: 26 train-loss: 1.3250888969852472\n",
      "Epoch: 27 train-loss: 1.3246306541886157\n",
      "Epoch: 28 train-loss: 1.3243063118920397\n",
      "Epoch: 29 train-loss: 1.3238933096562366\n",
      "Epoch: 30 train-loss: 1.3235664327007366\n",
      "Epoch: 31 train-loss: 1.3231712899990935\n",
      "[[1.392573175653974, 1.335429245220827, 1.3349396206422655, 1.3345284047665626, 1.334141177409239, 1.3336659580913943, 1.3331648065591417, 1.332785119125838, 1.3322912002168994, 1.3318587798299566, 1.3314267747691955, 1.3310293271851692, 1.3305529856732659, 1.3302075382488876, 1.3297732407604452, 1.329337861746359, 1.3289103279235774, 1.328510975786872, 1.3281544403735, 1.3277705742606223, 1.327350713805095, 1.3269293989453996, 1.326589594771867, 1.3261787843094197, 1.3257487544627078, 1.325369930470676, 1.3250888969852472, 1.3246306541886157, 1.3243063118920397, 1.3238933096562366, 1.3235664327007366, 1.3231712899990935]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 523.0692 seconds.\n",
      "Kernel: 8x8\n",
      "Epoch: 32\n",
      "Accuracy: 0.5987\n",
      "F1-score: 0.5435898939887255\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66, 0.4613, 0.5785, 0.5985, 0.546, 0.5987]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315, 0.4086, 0.523, 0.5334, 0.4815, 0.5436]\n",
      "8\n",
      "64\n",
      "Epoch: 0 train-loss: 1.4397534495477737\n",
      "Epoch: 1 train-loss: 1.3860409183542866\n",
      "Epoch: 2 train-loss: 1.3856941054878966\n",
      "Epoch: 3 train-loss: 1.3853832818806044\n",
      "Epoch: 4 train-loss: 1.3851075947665965\n",
      "Epoch: 5 train-loss: 1.3847363465376246\n",
      "Epoch: 6 train-loss: 1.3844448597446433\n",
      "Epoch: 7 train-loss: 1.3841518267893842\n",
      "Epoch: 8 train-loss: 1.3837999166456112\n",
      "Epoch: 9 train-loss: 1.3834704572458003\n",
      "Epoch: 10 train-loss: 1.383209587160204\n",
      "Epoch: 11 train-loss: 1.3829087031675553\n",
      "Epoch: 12 train-loss: 1.3825894899205613\n",
      "Epoch: 13 train-loss: 1.3822834123172232\n",
      "Epoch: 14 train-loss: 1.3819277670337702\n",
      "Epoch: 15 train-loss: 1.3816239185678933\n",
      "Epoch: 16 train-loss: 1.3813580681266053\n",
      "Epoch: 17 train-loss: 1.381008545981287\n",
      "Epoch: 18 train-loss: 1.380758285522461\n",
      "Epoch: 19 train-loss: 1.3804609900090232\n",
      "Epoch: 20 train-loss: 1.3802037480543417\n",
      "Epoch: 21 train-loss: 1.3798510921535208\n",
      "Epoch: 22 train-loss: 1.379585931041856\n",
      "Epoch: 23 train-loss: 1.3792487657400592\n",
      "Epoch: 24 train-loss: 1.3789369765121038\n",
      "Epoch: 25 train-loss: 1.37867071328641\n",
      "Epoch: 26 train-loss: 1.3783335543390531\n",
      "Epoch: 27 train-loss: 1.3780548386990643\n",
      "Epoch: 28 train-loss: 1.3777120941991745\n",
      "Epoch: 29 train-loss: 1.3774483450440203\n",
      "Epoch: 30 train-loss: 1.3772078134866157\n",
      "Epoch: 31 train-loss: 1.376897351319856\n",
      "Epoch: 32 train-loss: 1.3766062170711917\n",
      "Epoch: 33 train-loss: 1.3762886737709614\n",
      "Epoch: 34 train-loss: 1.3760416756814986\n",
      "Epoch: 35 train-loss: 1.3757406043599663\n",
      "Epoch: 36 train-loss: 1.3754721745244984\n",
      "Epoch: 37 train-loss: 1.375155992345261\n",
      "Epoch: 38 train-loss: 1.3749273847669428\n",
      "Epoch: 39 train-loss: 1.3746352005106555\n",
      "Epoch: 40 train-loss: 1.3743248855127201\n",
      "Epoch: 41 train-loss: 1.374077514544733\n",
      "Epoch: 42 train-loss: 1.3737450370402224\n",
      "Epoch: 43 train-loss: 1.373490093867662\n",
      "Epoch: 44 train-loss: 1.3731761136288836\n",
      "Epoch: 45 train-loss: 1.3728744803207007\n",
      "Epoch: 46 train-loss: 1.3725684886293879\n",
      "Epoch: 47 train-loss: 1.372262094320773\n",
      "Epoch: 48 train-loss: 1.371979576184043\n",
      "Epoch: 49 train-loss: 1.371727832598981\n",
      "Epoch: 50 train-loss: 1.3714835473469325\n",
      "Epoch: 51 train-loss: 1.3712031495596555\n",
      "Epoch: 52 train-loss: 1.37093048868403\n",
      "Epoch: 53 train-loss: 1.3705714575009051\n",
      "Epoch: 54 train-loss: 1.3702567749694465\n",
      "Epoch: 55 train-loss: 1.3700776489050404\n",
      "Epoch: 56 train-loss: 1.3698180583494304\n",
      "Epoch: 57 train-loss: 1.369508131226497\n",
      "Epoch: 58 train-loss: 1.3691964756959536\n",
      "Epoch: 59 train-loss: 1.368995821552236\n",
      "Epoch: 60 train-loss: 1.3686571960001865\n",
      "Epoch: 61 train-loss: 1.3683586923806652\n",
      "Epoch: 62 train-loss: 1.3681141552386253\n",
      "Epoch: 63 train-loss: 1.3678101153770235\n",
      "[[1.4397534495477737, 1.3860409183542866, 1.3856941054878966, 1.3853832818806044, 1.3851075947665965, 1.3847363465376246, 1.3844448597446433, 1.3841518267893842, 1.3837999166456112, 1.3834704572458003, 1.383209587160204, 1.3829087031675553, 1.3825894899205613, 1.3822834123172232, 1.3819277670337702, 1.3816239185678933, 1.3813580681266053, 1.381008545981287, 1.380758285522461, 1.3804609900090232, 1.3802037480543417, 1.3798510921535208, 1.379585931041856, 1.3792487657400592, 1.3789369765121038, 1.37867071328641, 1.3783335543390531, 1.3780548386990643, 1.3777120941991745, 1.3774483450440203, 1.3772078134866157, 1.376897351319856, 1.3766062170711917, 1.3762886737709614, 1.3760416756814986, 1.3757406043599663, 1.3754721745244984, 1.375155992345261, 1.3749273847669428, 1.3746352005106555, 1.3743248855127201, 1.374077514544733, 1.3737450370402224, 1.373490093867662, 1.3731761136288836, 1.3728744803207007, 1.3725684886293879, 1.372262094320773, 1.371979576184043, 1.371727832598981, 1.3714835473469325, 1.3712031495596555, 1.37093048868403, 1.3705714575009051, 1.3702567749694465, 1.3700776489050404, 1.3698180583494304, 1.369508131226497, 1.3691964756959536, 1.368995821552236, 1.3686571960001865, 1.3683586923806652, 1.3681141552386253, 1.3678101153770235]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Elapsed time: 986.3733 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: 8x8\n",
      "Epoch: 64\n",
      "Accuracy: 0.5221\n",
      "F1-score: 0.4556375509426431\n",
      "\n",
      "\n",
      "[0.631, 0.4491, 0.3148, 0.5873, 0.5816, 0.66, 0.4613, 0.5785, 0.5985, 0.546, 0.5987, 0.5221]\n",
      "[0.6063, 0.369, 0.2021, 0.5254, 0.5266, 0.6315, 0.4086, 0.523, 0.5334, 0.4815, 0.5436, 0.4556]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Iterate over the search space (kernel sizes and epochs) and record \n",
    "key evaluation metrics after each model. The experiment will result\n",
    "in 12 models with their metrics.\n",
    "\"\"\";\n",
    "\n",
    "experiment_losses = []\n",
    "experiment_model_accs = []\n",
    "experiment_model_f1s = []\n",
    "\n",
    "for kernel_size in SEARCH_SPACE.keys():\n",
    "    for epoch in SEARCH_SPACE[kernel_size]:\n",
    "        print(kernel_size)\n",
    "        print(epoch)\n",
    "        \n",
    "        # Decide which padding to use\n",
    "        padding = 0\n",
    "        if kernel_size == 6:\n",
    "            padding = 1\n",
    "        if kernel_size == 8:\n",
    "            padding = 2\n",
    "            \n",
    "        current_model, current_model_losses = train_model_2(epoch, kernel_size, padding)\n",
    "        _, current_model_acc, _, _, current_model_f1 = evaluate_model(current_model[0])\n",
    "        \n",
    "        print(f\"Kernel: {kernel_size}x{kernel_size}\\n\"\\\n",
    "              f\"Epoch: {epoch}\\n\"\n",
    "              f\"Accuracy: {current_model_acc}\\n\"\n",
    "              f\"F1-score: {current_model_f1}\\n\\n\")\n",
    "        \n",
    "        experiment_model_accs.append(round(current_model_acc, 4))\n",
    "        experiment_model_f1s.append(round(current_model_f1, 4))\n",
    "        experiment_losses.append(current_model_losses)\n",
    "        \n",
    "        print(experiment_model_accs)\n",
    "        print(experiment_model_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Surface(\n",
    "            z=np.array(experiment_model_accs).reshape(4,3),\n",
    "            x=[4, 6, 8, ],\n",
    "            y=[8, 16, 32, 64,],\n",
    "        ),\n",
    "        go.Surface(\n",
    "            z=np.array(experiment_model_f1s).reshape(4,3),\n",
    "            x=[4, 6, 8, ],\n",
    "            y=[8, 16, 32, 64,],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.update_traces(contours_z=dict(\n",
    "    show=True,\n",
    "    usecolormap=True,\n",
    "    highlightcolor=\"limegreen\",\n",
    "    project_z=True,\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Accuracy & F1-Score over Kernel Size and no. of Epochs',\n",
    "    autosize=True,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    margin=dict(\n",
    "        l=65,\n",
    "        r=50,\n",
    "        b=65,\n",
    "        t=90, ),\n",
    ")\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),  # z-axis up\n",
    "    center=dict(x=0, y=0, z=0),  # default\n",
    "    eye=dict(x=1.5, y=1.5, z=0.8)\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Kernel size',\n",
    "        yaxis_title='# Epochs',\n",
    "        zaxis_title='Test Accuracy',\n",
    "        xaxis=dict(nticks=3, range=[4, 8],),\n",
    "        yaxis=dict(nticks=4, range=[8, 64],),\n",
    "        zaxis=dict(nticks=10, range=[0.1, 0.7],),\n",
    "    ),\n",
    "    scene_camera=camera,\n",
    ")\n",
    "fig.write_html('./plots/surface_plot.html')\n",
    "#fig.show()  # comment out if problems with WebGL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< WebGl causes problems with plotting a 3D plot in google colab. >  \n",
    "The surface plot displays the accuracy and the average f1-scores for each model. We can observe a slight trend upwards with increasing epochs and a dip at kernel size 6x6 across all epochs. I did not know that accuracy and f1-score are that close related, but it makes sense because they assess the same metric (value counts per class) and scale it down between 0 and 1. The upper surface is accuracy and the lower surface are the f1-scores.  \n",
    "Note that the z-axis is scaled between 0.1 and 0.7.\n",
    "\n",
    "<img align=\"center\" style=\"max-width: 600px\" src=\"./plots/surface_plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "# Epochs: %{x}<br>Kernel Size: %{y}<br>Accuracy: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "*8",
          "*16",
          "*32",
          "*64"
         ],
         "xaxis": "x",
         "y": [
          "*4",
          "*6",
          "*8"
         ],
         "yaxis": "y",
         "z": [
          [
           0.631,
           0.5873,
           0.4613,
           0.546
          ],
          [
           0.4491,
           0.5816,
           0.5785,
           0.5987
          ],
          [
           0.3148,
           0.66,
           0.5985,
           0.5221
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmax": 1,
         "cmin": 0,
         "colorbar": {
          "title": {
           "text": "Accuracy"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "title": {
         "text": "Model Comparison"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "# Epochs"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Kernel Size"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5609a1f0-50ed-4980-a427-63aa9ea806ef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5609a1f0-50ed-4980-a427-63aa9ea806ef\")) {                    Plotly.newPlot(                        \"5609a1f0-50ed-4980-a427-63aa9ea806ef\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"# Epochs: %{x}<br>Kernel Size: %{y}<br>Accuracy: %{z}<extra></extra>\",\"name\":\"0\",\"type\":\"heatmap\",\"x\":[\"*8\",\"*16\",\"*32\",\"*64\"],\"xaxis\":\"x\",\"y\":[\"*4\",\"*6\",\"*8\"],\"yaxis\":\"y\",\"z\":[[0.631,0.5873,0.4613,0.546],[0.4491,0.5816,0.5785,0.5987],[0.3148,0.66,0.5985,0.5221]]}],                        {\"coloraxis\":{\"cmax\":1,\"cmin\":0,\"colorbar\":{\"title\":{\"text\":\"Accuracy\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"title\":{\"text\":\"Model Comparison\"},\"xaxis\":{\"anchor\":\"y\",\"constrain\":\"domain\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"title\":{\"text\":\"# Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"autorange\":\"reversed\",\"constrain\":\"domain\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Kernel Size\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5609a1f0-50ed-4980-a427-63aa9ea806ef');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.imshow(\n",
    "    np.array(experiment_model_accs).reshape(4,3).T,\n",
    "    title='Model Comparison',\n",
    "    template='none',\n",
    "    labels=dict(\n",
    "        x='# Epochs', \n",
    "        y='Kernel Size', \n",
    "        color='Accuracy',\n",
    "    ),\n",
    "    x=['*8', '*16', '*32', '*64',],\n",
    "    y=['*4', '*6', '*8', ],\n",
    "    aspect='equal',\n",
    "    color_continuous_scale='RdBu',\n",
    "    zmin=0, \n",
    "    zmax=1,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\"\"\"\n",
    "The surface plot can be sclaed down to a simple heatmap aswell. \n",
    "The color is scaled between 0 and 1. This illustrates that the\n",
    "models are each closely related. None shows a much much better \n",
    "performance.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_loss, model_2_acc, model_2_report, model_2_cm, model_2_f1 = evaluate_model(current_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.374875545501709\n",
      "Accuracy: 0.5221\n",
      "F1-score: 0.4556375509426431\n",
      "Classiification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63      1000\n",
      "           1       0.62      0.89      0.73      1000\n",
      "           2       0.42      0.62      0.50      1000\n",
      "           3       0.53      0.32      0.40      1000\n",
      "           4       0.41      0.47      0.44      1000\n",
      "           5       0.48      0.31      0.38      1000\n",
      "           6       0.12      0.01      0.01      1000\n",
      "           7       0.95      0.04      0.08      1000\n",
      "           8       0.54      0.88      0.67      1000\n",
      "           9       0.56      0.99      0.72      1000\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.52      0.52      0.46     10000\n",
      "weighted avg       0.52      0.52      0.46     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {model_2_loss}\")\n",
    "print(f\"Accuracy: {model_2_acc}\")\n",
    "print(f\"F1-score: {model_2_f1}\")\n",
    "print(\"Classiification report:\")\n",
    "print(model_2_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "True Label: %{x}<br>Predicted Label: %{y}<br>Hits: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "T-shirt/top",
          "Trouser",
          "Pullover",
          "Dress",
          "Coat",
          "Sandal",
          "Shirt",
          "Sneaker",
          "Bag",
          "Ankle boot"
         ],
         "xaxis": "x",
         "y": [
          "T-shirt/top",
          "Trouser",
          "Pullover",
          "Dress",
          "Coat",
          "Sandal",
          "Shirt",
          "Sneaker",
          "Bag",
          "Ankle boot"
         ],
         "yaxis": "y",
         "z": [
          [
           692,
           33,
           120,
           93,
           21,
           0,
           17,
           0,
           20,
           4
          ],
          [
           34,
           893,
           11,
           50,
           6,
           0,
           3,
           0,
           2,
           1
          ],
          [
           32,
           3,
           618,
           8,
           279,
           0,
           9,
           0,
           50,
           1
          ],
          [
           151,
           464,
           19,
           315,
           36,
           0,
           11,
           0,
           2,
           2
          ],
          [
           78,
           17,
           339,
           57,
           469,
           0,
           20,
           0,
           19,
           1
          ],
          [
           0,
           4,
           0,
           0,
           0,
           314,
           0,
           1,
           267,
           414
          ],
          [
           208,
           21,
           318,
           57,
           307,
           0,
           8,
           0,
           79,
           2
          ],
          [
           0,
           0,
           0,
           0,
           0,
           326,
           0,
           42,
           313,
           319
          ],
          [
           2,
           12,
           50,
           14,
           14,
           1,
           0,
           0,
           884,
           23
          ],
          [
           0,
           1,
           0,
           0,
           0,
           7,
           0,
           1,
           5,
           986
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmax": 1000,
         "cmin": 0,
         "colorbar": {
          "title": {
           "text": "Hits"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "title": {
         "text": "Confusion Matrix"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "True Label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Predicted Label"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"bfb22415-1d1d-4967-8652-169c96833431\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bfb22415-1d1d-4967-8652-169c96833431\")) {                    Plotly.newPlot(                        \"bfb22415-1d1d-4967-8652-169c96833431\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"True Label: %{x}<br>Predicted Label: %{y}<br>Hits: %{z}<extra></extra>\",\"name\":\"0\",\"type\":\"heatmap\",\"x\":[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"],\"xaxis\":\"x\",\"y\":[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"],\"yaxis\":\"y\",\"z\":[[692,33,120,93,21,0,17,0,20,4],[34,893,11,50,6,0,3,0,2,1],[32,3,618,8,279,0,9,0,50,1],[151,464,19,315,36,0,11,0,2,2],[78,17,339,57,469,0,20,0,19,1],[0,4,0,0,0,314,0,1,267,414],[208,21,318,57,307,0,8,0,79,2],[0,0,0,0,0,326,0,42,313,319],[2,12,50,14,14,1,0,0,884,23],[0,1,0,0,0,7,0,1,5,986]]}],                        {\"coloraxis\":{\"cmax\":1000,\"cmin\":0,\"colorbar\":{\"title\":{\"text\":\"Hits\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"title\":{\"text\":\"Confusion Matrix\"},\"xaxis\":{\"anchor\":\"y\",\"constrain\":\"domain\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"title\":{\"text\":\"True Label\"}},\"yaxis\":{\"anchor\":\"x\",\"autorange\":\"reversed\",\"constrain\":\"domain\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Predicted Label\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('bfb22415-1d1d-4967-8652-169c96833431');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.imshow(\n",
    "    model_2_cm,\n",
    "    title='Confusion Matrix',\n",
    "        labels=dict(\n",
    "        x=\"True Label\", \n",
    "        y=\"Predicted Label\",\n",
    "        color=\"Hits\",\n",
    "    ),\n",
    "    x=[*CLASSES.values()],\n",
    "    y=[*CLASSES.values()],\n",
    "    template='none',\n",
    "    aspect='equal',\n",
    "    color_continuous_scale='RdBu',\n",
    "    zmin=0, \n",
    "    zmax=1000,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\"\"\"\n",
    "The confusion matrix shows an improved 'learning' across classes.\n",
    "When compared to the vanilla model more classes are predicted correctly.\n",
    "\"\"\";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
